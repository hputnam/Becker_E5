---
title: "RNA_seq_DESeq2"
author: "echille"
edited by: "daniellembecker"
date: "4/12/2021"
output: html_document
---

# Molecular Underpinnings Chronic Nutrient Enrichment Project

## RNAseq Differential Expression Analysis 
## Follow RNAseq workflow in Bioinformatics>RNAseq>RNAseq workflow before statistical analysis to make gene counts and transcript counts matrices

### Set up workspace

Load libraries
```{r, message=FALSE, warning=FALSE}
library("genefilter")
library("car")
library("DESeq2")
library("factoextra")
library("MuMIn")
library("NbClust")
library("ComplexHeatmap")
library("tidyverse")
library("tidyr")
library("lme4")
library("RColorBrewer")
library("magrittr")
library("ggplot2")
library("goseq")
library("gridExtra")
library("VennDiagram")
library("here")
```

Import the data files 
```{r}
#treatment information
treatmentinfo <- read.csv("../Data/RNA-seq/metadata.RNAseq.csv", header = TRUE, sep = ",")
rownames(treatmentinfo) <- treatmentinfo$sample_id
str(treatmentinfo)
head(treatmentinfo)

#gene count matrix
gcount <- as.data.frame(read.csv("../Data/RNA-seq/Poc_gene_count_matrix.csv", row.names="gene_id"))
dim(gcount)
head(gcount)

#remove extra characters from multiple column header names for sample ids, skip first column labeled gene counts so specify 1:ncol
for ( col in 1:ncol(gcount)){
  colnames(gcount)[col] <-  sub("_R1_001.fastq.gz.sam.sorted.bam.merge.gtf", "", colnames(gcount)[col])
}

#subset the gcount matrix and reorder it so it matches the treatment info
gcount <- gcount[ ,treatmentinfo$sample_id]
head(gcount)

# Make sure treatment info ='s the rows of count data
all(rownames(treatmentinfo) %in% colnames(gcount)) # must come out TRUE

```


##### Pre-filter gene counts
## Pre-filtering our dataset to reduce the memory size dataframe, increase the speed of the transformation and testing functions, and improve quality of statistical analysis by removing low-coverage counts. Removed counts could represent outliers in the data and removing these improves sensitivity of statistical tests. We will filter out low coverage samples. Here, we will keep P=87.5% percent of the samples have counts over A=5, allowing only 1 of 8 samples to have a value less than 5 per gene.

```{r}
#Set filter values for PoverA, P=87.5% percent of the samples have counts over A=5. We chose this value allowing only 1 of 8 samples to have a value less than 5 per gene. 
filt <- filterfun(pOverA(0.875,5))

#create filter for the counts data
gfilt <- genefilter(gcount, filt)

#identify genes to keep by count filter
gkeep <- gcount[gfilt,]

#identify gene lists
gn.keep <- rownames(gkeep)

#gene count data filtered in PoverA, P percent of the samples have counts over A
gcount_filt <- as.data.frame(gcount[which(rownames(gcount) %in% gn.keep),])
head(gcount_filt)
dim(gcount_filt)

```

##Merge the treatment columns into a new column , group. Set group as a factor.
```{r}
treatmentinfo$treatment <- factor(treatmentinfo$treatment, levels = c("control","enriched"))
```

#Create a DESeqDataSet design from gene count matrix and labels. Here we set the design to look at treatment to test for any differences in gene expression across timepoints attributed to treatment.
#not using DESeq due to random factors, but can still use this to visualize clusters
```{r}
#Set DESeq2 design
gdds <- DESeqDataSetFromMatrix(countData = gcount_filt,
                              colData = treatmentinfo,
                              design = ~treatment)
```

#### Visualize gene count data

We're looking to see if the samples of the same treatments cluster

##### Log-transform the count data
First we are going to log-transform the data using a variance stabilizing transforamtion (vst). This is only for visualization purposes. Essentially, this is roughly similar to putting the data on the log2 scale. It will deal with the sampling variability of low counts by calculating within-group variability (if blind=FALSE). Importantly, it does not use the design to remove variation in the data, and so can be used to examine if there may be any variability do to technical factors such as extraction batch effects.

To do this we first need to calculate the size factors of our samples. This is a rough estimate of how many reads each sample contains compared to the others. In order to use VST (the faster log2 transforming process) to log-transform our data, the size factors need to be less than 4. Otherwise, there could be artefacts in our results.
```{r}
SF.gdds <- estimateSizeFactors(gdds) #estimate size factors to determine if we can use vst  to transform our data. Size factors should be less than four to use vst
print(sizeFactors(SF.gdds)) #View size factors
```

Our size factors are all less than 4, so we can use VST!
```{r}
gvst <- vst(gdds, blind=FALSE) #apply a variance stabilizing transformation to minimize effects of small counts and normalize wrt library size
```

#### Principal component plot of samples
```{r}
gPCAdata <- plotPCA(gvst, intgroup = c("treatment"), returnData=TRUE)
percentVar <- round(100*attr(gPCAdata, "percentVar")) #plot PCA of samples with all data
ggplot(gPCAdata, aes(PC1, PC2, color=treatment)) + 
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  scale_color_manual(values = c(control="slateblue", enriched="indianred3")) +
  coord_fixed() +
  theme_bw() + #Set background color
  theme(panel.border = element_blank(), # Set border
                     #panel.grid.major = element_blank(), #Set major gridlines
                     #panel.grid.minor = element_blank(), #Set minor gridlines
                     axis.line = element_line(colour = "black"), #Set axes color
        plot.background=element_blank()) + #Set the plot background
  theme(legend.position = ("none")) #set title attributes
```

##### Run DE analysis for overall example 

Run differential expression test using a Wald model. 
```{r, message = FALSE}
DEG_enriched <- DESeq(gdds) #run differential expression test by group using the Wald model
```

Explore significant p-values for treatment
```{r, message = FALSE}
DEG.results <- results(DEG_enriched, contrast=c("treatment","control","enriched"))
head(DEG.results)
sum(DEG.results$padj < 0.05, na.rm=TRUE) #How many adjusted p-values were less than 0.05?

```

#### Differential Gene Expression Analysis
# For data with random effects

```{r}
#reshape count data and join data frames for treatment and gene counts
head(gcount_filt)

#preserve rownames in data frame while converting data frame from wide to long format
gcount_filt_long <- gcount_filt %>% 
    as_tibble(rownames = "gene_id") %>% 
    pivot_longer(cols = -gene_id, names_to = "sample_id", values_to = "count")

head(gcount_filt_long)

#join treatment information with gene count data so gene_ids can be assigned to samples and treatments
combined.data <- left_join(gcount_filt_long, treatmentinfo)

view(combined.data)
```

#### Fit glmer position model

```{r}
# create data frame to store results
results <- data.frame()
gs <- unique(combined.data$gene_id)

#make block a factor 
combined.data$block <- as.factor(combined.data$block)

```


```{r}
#think about this as just a logistic regression, just adding a random effect for block. P-values based off of maximum likelihood approach, not gonna be like an anova table.
# for loop is sub-setting the combined data sheet to go through gene by gene and compare treatment by the count data 
# we found that we needed to use a summary table for glmer models in R and pull the coefficients to observed the p values for this type of model. We picked coefficient number 8 because that was the column and row that had our p value data between treatments
# to be confident with our for loop, we first used ggplot to visualize one gene with treatment and count data and saw that the data aligned how we expected for a gene that was insignificant

for(i in 1:length((combined.data$gene_id))){
  
  #subset the dataframe gene by gene
  combined.data1 <- subset(combined.data, gene_id == gs[i])
  
  fit <- glmer(count ~ treatment + (1 | treatment:block), family="poisson", data=combined.data1)
  
  a <- summary(fit)
  
  # capture summary stats to data frame
  df <- data.frame(gene = combined.data1[1,1],
                   pval.treatment = a$coefficients[8])
  
  # bind rows of temporary data frame to the results data frame
  results <- rbind(results, df)
}

```

```{r}
#wanted to compare models to double check and verify the format of models, for comparing how certain ways of nesting block within treatment impact AIC and model trends
#want a model that will treat all blocks within one treatment different, fit independent models to all blocks in one treatment, will account for inter-treatment variability 

model1 <- glmer(count ~ treatment + (1 | treatment:block), 
             data=combined.data1, family="poisson")

model2 <- glmer(count ~ treatment + (1|block), 
             data=combined.data1, family="poisson")

model3 <- glmer(count ~ treatment + (1|treatment/block), 
             data=combined.data1, family="poisson")

#model.sel in MuMIn package for a model comparison function

model.sel(model1, model2)

#results based of of model, so need to check residuals of the model for normality and also for homogeneity of variance within the model
#check histogram of residuals for model1, normality of residuals

qqPlot(residuals(model1))

#homogeneity of variance levene test, < 0.05 have a violation in variance, we do not have a violation, all good, standard error around mean is approx. the same around each group

leveneTest(residuals(model1)~combined.data1$treatment)

```

Explore significant p values between treatments
```{r}
#How many adjusted p-values were less than 0.05?

sum(results$pval.treatment < 0.05, na.rm=TRUE) 

#create data frame with only DEG's with < 0.05 significance 

DEG.sig.results <- subset(results, pval.treatment < 0.05)

write.csv(DEG.sig.results, '../Data/RNA-seq/DEG.sig.results.csv')  

```

