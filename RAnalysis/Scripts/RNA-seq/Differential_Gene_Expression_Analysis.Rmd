---
title: "RNA_seq_DESeq2"
author: "echille"
edited by: "daniellembecker"
date: "4/12/2021"
output: html_document
---

# Molecular Underpinnings Chronic Nutrient Enrichment Project

## RNAseq Differential Expression Analysis 
## Follow RNAseq workflow in Bioinformatics>RNAseq>RNAseq workflow before statistical analysis to make gene counts and transcript counts matrices

### Set up workspace

Load libraries
```{r, message=FALSE, warning=FALSE}
library("genefilter")
library("car")
library("DESeq2")
library("factoextra")
library("MuMIn")
library("NbClust")
library("ComplexHeatmap")
library("tidyverse")
library("tidyr")
library("lme4")
library("RColorBrewer")
library("magrittr")
library("ggplot2")
library("goseq")
library("gridExtra")
library("VennDiagram")
library("here")
```

Import the data files 
```{r}
#treatment information
treatmentinfo <- read.csv("../../Data/RNA-seq/metadata.RNAseq.csv", header = TRUE, sep = ",")
rownames(treatmentinfo) <- treatmentinfo$sample_id
str(treatmentinfo)
head(treatmentinfo)

#gene count matrix
gcount <- as.data.frame(read.csv("../../Data/RNA-seq/Poc_gene_count_matrix.csv", row.names="gene_id"))
dim(gcount)
head(gcount)

#remove extra characters from multiple column header names for sample ids, skip first column labeled gene counts so specify 1:ncol
for ( col in 1:ncol(gcount)){
  colnames(gcount)[col] <-  sub("_R1_001.fastq.gz.sam.sorted.bam.merge.gtf", "", colnames(gcount)[col])
}

#subset the gcount matrix and reorder it so it matches the treatment info
gcount <- gcount[ ,treatmentinfo$sample_id]
head(gcount)

# Make sure treatment info ='s the rows of count data
all(rownames(treatmentinfo) %in% colnames(gcount)) # must come out TRUE

```


##### Pre-filter gene counts
## Pre-filtering our dataset to reduce the memory size dataframe, increase the speed of the transformation and testing functions, and improve quality of statistical analysis by removing low-coverage counts. Removed counts could represent outliers in the data and removing these improves sensitivity of statistical tests. We will filter out low coverage samples. Here, we will keep P=87.5% percent of the samples have counts over A=5, allowing only 1 of 8 samples to have a value less than 5 per gene.

```{r}
#Erin Set filter values for PoverA, P=87.5% percent of the samples have counts over A=5. We chose this value allowing only 1 of 8 samples to have a value less than 5 per gene. 
filt <- filterfun(pOverA(0.875,5))

#create filter for the counts data
gfilt <- genefilter(gcount, filt)

#identify genes to keep by count filter
gkeep <- gcount[gfilt,]

#identify gene lists
gn.keep <- rownames(gkeep)

#gene count data filtered in PoverA, P percent of the samples have counts over A
gcount_filt <- as.data.frame(gcount[which(rownames(gcount) %in% gn.keep),])
head(gcount_filt)
dim(gcount_filt)


```

#testing PoverA cut off values and influence on differential expression number and change in enrichment

```{r}
#make data frame to test the change in the PoverA results to see how much our differential expression number and enrichment changes for the PoverA
#set PoverA at 0.50, 0.60, 0.60, 0.70, 0.80, 0.90, and 1.0

PoverA_cut_off <- c(0.50, 0.60, 0.70, 0.80, 0.85, 0.86, 0.87, 0.88, 0.89, 0.90, 1.0)
diff.expres.num <- c(20306, 19685, 19163, 18601, 18108, 18108, 18108, 17804, 17804, 17804, 16088)

povera_test <- data_frame(PoverA_cut_off, diff.expres.num)

ggplot(povera_test, aes(x = PoverA_cut_off, y = diff.expres.num)) +
  geom_point() 

```


##Merge the treatment columns into a new column , group. Set group as a factor.
```{r}
treatmentinfo$treatment <- factor(treatmentinfo$treatment, levels = c("control","enriched"))
```

#Create a DESeqDataSet design from gene count matrix and labels. Here we set the design to look at treatment to test for any differences in gene expression across timepoints attributed to treatment.
#not using DESeq due to random factors, but can still use this to visualize clusters
```{r}
#Set DESeq2 design
gdds <- DESeqDataSetFromMatrix(countData = gcount_filt,
                              colData = treatmentinfo,
                              design = ~treatment)
```

#### Visualize gene count data

We're looking to see if the samples of the same treatments cluster

##### Log-transform the count data
First we are going to log-transform the data using a variance stabilizing transforamtion (vst). This is only for visualization purposes. Essentially, this is roughly similar to putting the data on the log2 scale. It will deal with the sampling variability of low counts by calculating within-group variability (if blind=FALSE). Importantly, it does not use the design to remove variation in the data, and so can be used to examine if there may be any variability do to technical factors such as extraction batch effects.

To do this we first need to calculate the size factors of our samples. This is a rough estimate of how many reads each sample contains compared to the others. In order to use VST (the faster log2 transforming process) to log-transform our data, the size factors need to be less than 4. Otherwise, there could be artefacts in our results.
```{r}
SF.gdds <- estimateSizeFactors(gdds) #estimate size factors to determine if we can use vst  to transform our data. Size factors should be less than four to use vst
print(sizeFactors(SF.gdds)) #View size factors
```

Our size factors are all less than 4, so we can use VST!
```{r}
gvst <- vst(gdds, blind=FALSE) #apply a variance stabilizing transformation to minimize effects of small counts and normalize wrt library size
```

#### Principal component plot of samples
```{r}
gPCAdata <- plotPCA(gvst, intgroup = c("treatment"), returnData=TRUE)
percentVar <- round(100*attr(gPCAdata, "percentVar")) #plot PCA of samples with all data
ggplot(gPCAdata, aes(PC1, PC2, color=treatment)) + 
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  scale_color_manual(values = c(control="slateblue", enriched="indianred3")) +
  coord_fixed() +
  theme_bw() + #Set background color
  theme(panel.border = element_blank(), # Set border
                     #panel.grid.major = element_blank(), #Set major gridlines
                     #panel.grid.minor = element_blank(), #Set minor gridlines
                     axis.line = element_line(colour = "black"), #Set axes color
        plot.background=element_blank()) + #Set the plot background
  theme(legend.position = ("none")) #set title attributes
```

##### Run DE analysis for overall example 

Run differential expression test using a Wald model. 
```{r, message = FALSE}
DEG_enriched <- DESeq(gdds) #run differential expression test by group using the Wald model
```

Explore significant p-values for treatment
```{r, message = FALSE}
DEG.results <- results(DEG_enriched, contrast=c("treatment","control","enriched")) #see code underlying function is to apply to glmer DEG results, FDR correction
head(DEG.results)
sum(DEG.results$padj < 0.05, na.rm=TRUE) #How many adjusted p-values were less than 0.05?

#create data frame with only DESeq2 DEG's with < 0.05 significance 

DEGSeq2.sig.results <- subset(DEG.results, padj < 0.05)

```

#### Differential Gene Expression Analysis
# For data with random effects

```{r}
#reshape count data and join data frames for treatment and gene counts
head(gcount_filt)

#preserve rownames in data frame while converting data frame from wide to long format
gcount_filt_long <- gcount_filt %>% 
    as_tibble(rownames = "gene_id") %>% 
    pivot_longer(cols = -gene_id, names_to = "sample_id", values_to = "count")

head(gcount_filt_long)

#join treatment information with gene count data so gene_ids can be assigned to samples and treatments
combined.data <- left_join(gcount_filt_long, treatmentinfo)

view(combined.data)
```

#### Fit glmer position model

```{r}
# create data frame to store results
results <- data.frame()
gs <- unique(combined.data$gene_id)

#make block a factor 
combined.data$block <- as.factor(combined.data$block)

```


```{r}

#Notes on 0615:
#Found a way to resolve the error, for the for loop, length needed to be amended to just look through the gs data frame, the length for combined.data:gene_id was going through each observation and not just looking at the unique genes

#Notes on 0608: 
#last thing I did was run random effect (block) as fixed factor but when I do summary, block 8 has NA's, maybe an issue with formatting/subsetting section? TBD
#the "Error: Invalid grouping factor specification, 1 = block" is only occurring for certain gene ID and sample pairs.
#when I selected i after the error was reported in the for loop, it said line 18109 which was gene ID g16996 was causing this error. I thought maybe E6's block had a typo or something associated with it did, but tried other gene ID's with the E6 line (which was taken from metadata sheet so all would be the same) and it ran through the model fine. I then thought maybe it was this gene ID, but other combinations I tried with this gene ID ran through the model fine. I then thought maybe it was gene ID's with the labeling gXXX but tried random gene ID's around this labeling and numbering and they still worked. So I do not think it is a typo but something about the specific combinations at this point.

#Notes on 0605:
#confident in model selection from below when checking with i = 1 and i = 30
#in for loop, receiving "Error: Invalid grouping factor specification, 1 = 1block" which others have run into and said it is due to NA values which are not present throughout our data frames
#when run individual i = 1 or i = 30 for glmer, will run fine without an error
#I also get the warning for boundary (singular) fit: see ?isSingular as the for loop runs which is saying that the random effects are not accounting for much more if any more variation in the model,
# ?isSingular explanation: complex mixed-effect models (i.e., those with a large number of variance-covariance parameters) frequently result in singular fits, i.e. estimated variance-covariance matrices with less than full rank. Less technically, this means that some "dimensions" of the variance-covariance matrix have been estimated as exactly zero. For scalar random effects such as intercept-only models, or 2-dimensional random effects such as intercept+slope models, singularity is relatively easy to detect because it leads to random-effect variance estimates of (nearly) zero, or estimates of correlations that are (almost) exactly -1 or 1.
#when run with DESeq2, 223 significant DEGs, when run with glmer 1,953

#Notes on 0526:
#think about this as just a logistic regression, just adding a random effect for block. P-values based off of maximum likelihood approach, not gonna be like an anova table.
# for loop is sub-setting the combined data sheet to go through gene by gene and compare treatment by the count data 
# we found that we needed to use a summary table for glmer models in R and pull the coefficients to observed the p values for this type of model. We picked coefficient number 8 because that was the column and row that had our p value data between treatments
# to be confident with our for loop, we first used ggplot to visualize one gene with treatment and count data and saw that the data aligned how we expected for a gene that was insignificant

combined.data <- na.omit(combined.data)

for(i in 1:length((gs))){
  
  #subset the dataframe gene by gene
  combined.data1 <- subset(combined.data, gene_id == gs[i])
  
  fit <- glmer(count ~ treatment + (1|block), family="poisson", data=combined.data1)
  
  a <- summary(fit)
  
  # capture summary stats to data frame
  df <- data.frame(gene = combined.data1[1,1],  #prints gene id into output table
                   pval.treatment = a$coefficients[8])   #prints pval from coefficients table
                   #random.variance = print(a$varcor, comp=c("Variance"))) #prints random effects variance value from model
  
  #remove extra columns created with varcorr for random effect results 
  
  #df2 <-  df[,-(3:5)]
  
  # bind rows of temporary data frame to the results data frame
  results <- rbind(results, df) 
  
}

```

```{r}
#notes on 0602:
#wanted to compare models to double check and verify the format of models, for comparing how certain ways of nesting block within treatment impact AIC and model trends
#want a model that will treat all blocks within one treatment different, fit independent models to all blocks in one treatment, will account for inter-treatment variability 
#using model 2 because model 1 and 2 had lowest AIC values and want to go with the least complex model because the added complexity is not adding any new information

model1 <- glmer(count ~ treatment + (1 | treatment:block), 
             data=combined.data1, family="poisson")

model2 <- glmer(count ~ treatment + (1|block), 
             data=combined.data1, family="poisson")

model3 <- glmer(count ~ treatment + (1|treatment/block), 
             data=combined.data1, family="poisson")

#model.sel in MuMIn package for a model comparison function

model.sel(model1, model2)

#results based of of model, so need to check residuals of the model for normality and also for homogeneity of variance within the model
#check histogram of residuals for model2, normality of residuals

qqPlot(residuals(model2))

#homogeneity of variance levene test, < 0.05 have a violation in variance, we do not have a violation, all good, standard error around mean is approx. the same around each group

leveneTest(residuals(model2)~combined.data1$treatment)

```

Explore significant p values between treatments
```{r}
#How many adjusted p-values were less than 0.05?

sum(results$pval.treatment < 0.05, na.rm=TRUE) 

#create data frame with only DEG's with < 0.05 significance 

DEG.sig.results <- subset(results, pval.treatment < 0.05)

write.csv(DEG.sig.results, '../../Output/RNA-seq/DEG/DEG.sig.results.csv')  

read.csv('../../Output/RNA-seq/DEG/DEG.sig.results.csv')  

#DEG.sig.results.corrected <- results(DEG.sig.results, contrast=c("treatment","control","enriched"), pAdjustMethod = "BH")

```



#### Fit glmer position model, testing with fake data set to test random effects and treatments in glmer are accounting for variance, etc. properly


```{r}
# bring in test data frame

test.data <- read.csv("../../Data/RNA-seq/test.data.glmer.sig.csv", header = TRUE, sep = ",")

```

```{r}
# create data frame to store results
results.test <- data.frame()
gs.test <- unique(test.data$gene_id)

#make block a factor 
test.data$block <- as.factor(test.data$block)
test.data$treatment <- as.factor(test.data$treatment)

```


```{r}

for(i in 1:length((gs.test))){
  
  #subset the dataframe gene by gene
  test.data1 <- subset(test.data, gene_id == gs.test[i])
  
  fit.test <- glmer(gene_count ~ treatment + (1|block), family="poisson", data=test.data1)
  
  a.test <- summary(fit.test)
  
  # capture summary stats to data frame
  df.test <- data.frame(gene = test.data1[1,1],  #prints gene id into output table
                   pval.treatment = a.test$coefficients[8])   #prints pval from coefficients table
  
  #remove extra columns created with varcorr for random effect results 
  
  #df2 <-  df[,-(3:5)]
  
  # bind rows of temporary data frame to the results data frame
  results.test <- rbind(results.test, df.test) 
  
}

```


```{r}
#use lattice package to compare block design and make sure it is effecting the variance with my test values with i = 1, i = 4, i = 3, i = 2. Everytime I made a different block have a greater effect and it did correctly calculate and observe that change in variation.

library(lattice)
str(rr1 <- ranef(fit.test))
dotplot(rr1)  ## default
qqmath(rr1)

```

